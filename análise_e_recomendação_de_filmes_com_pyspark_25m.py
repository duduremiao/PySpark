# -*- coding: utf-8 -*-
"""Análise e Recomendação de Filmes com PySpark_25M.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BRHOg4qFsSl5wuyEdIBhe6oAkvuLhVE2

# **Análise e Recomendação de Filmes com PySpark**

**Eduardo Arruda Remião e Rafael do Amaral Porciuncula**

---

**Instalar bibliotecas necessárias**
"""

!pip install pyspark findspark kagglehub matplotlib

"""---

**Importando bibliotecas necessárias**
"""

import findspark
findspark.init()

from pyspark.sql import SparkSession
from pyspark.sql.functions import col, count, avg, split, explode
import matplotlib.pyplot as plt

"""---

**Criar sessão Spark**
"""

spark = SparkSession.builder \
    .appName("MovieLens25M Analysis and Recommendations") \
    .getOrCreate()

"""---

**Baixar dataset do Kaggle**
"""

import kagglehub


path = kagglehub.dataset_download("garymk/movielens-25m-dataset")
print("Dataset saved at:", path)

"""---

**Caminhos para os arquivos do dataset MovieLens 25M**
"""

ratings_path = f"{path}/ml-25m/ratings.csv"
movies_path = f"{path}/ml-25m/movies.csv"

"""---

**Carregar os dados**



*   **sep=**"," : O separador usado nos arquivos CSV é uma vírgula (,)

*   **header=**True : Este parâmetro indica que a primeira linha do arquivo contém os nomes das colunas, ou seja, será usada como cabeçalho para o DataFrame.

*   **inferSchema=**True : Este parâmetro solicita que o PySpark automaticamente determine o tipo de dados de cada coluna com base nos valores presentes no arquivo CSV.
"""

# Carregar o arquivo de avaliações
ratings = spark.read.csv(
    ratings_path,
    sep=",",
    header=True,
    inferSchema=True
)

# Carregar o arquivo de filmes
movies = spark.read.csv(
    movies_path,
    sep=",",
    header=True,
    inferSchema=True
)

# Verificar esquemas
print("Esquema de Ratings:")
ratings.printSchema()

print("Esquema de Movies:")
movies.printSchema()

"""---

**Análise Exploratória**

*   **ratings.groupBy("movieId")** : Agrupa os dados do DataFrame ratings pela coluna movieId

*   **groupBy()** agrupa as avaliações por filme

*   **.count()** : conta quantas avaliações existem para cada filme

*   **.orderBy("count", ascending=False)** : O DataFrame é ordenado com base na coluna count (nº de avaliações) de forma decrescente (ascending=False).
"""

# Contagem de avaliações por filme
top_movies = ratings.groupBy("movieId") \
    .count() \
    .join(movies, "movieId") \
    .orderBy("count", ascending=False)

print("Top 10 filmes mais avaliados:")
top_movies.show(10, truncate=False)

"""---

**Exibir os 10 filmes com melhores médias (considerando pelo menos 10.000 avaliações)**

*   **ratings.groupBy("movieId")** : Agrupa as avaliações no DataFrame ratings pela coluna movieId
*   **.agg()** : Usada para realizar agregações nos grupos

*   **count("rating")** : Conta o número total de avaliações feitas para cada filme.
*  **avg("rating")** : Calcula a média das avaliações para cada filme

*   **.filter("num_ratings >= 10000")** : Mantém apenas os filmes que possuem pelo menos 10.000 avaliações

*   **.join(movies, "movieId")** : O DataFrame filtered_ratings é combinado com o DataFrame movies, que contém informações sobre os filmes

*   **.orderBy("average_rating", ascending=False)** : Ordenação pela coluna average_rating de forma decrescente (ascending=False)
"""

from pyspark.sql.functions import avg, count

# Contar número de avaliações por filme
ratings_count = ratings.groupBy("movieId") \
    .agg(
        count("rating").alias("num_ratings"),
        avg("rating").alias("average_rating")
    )

# Filtrar filmes com pelo menos 10.000 avaliações
filtered_ratings = ratings_count.filter("num_ratings >= 10000")

# Juntar com o DataFrame de filmes e ordenar por média de avaliação
average_ratings = filtered_ratings.join(movies, "movieId") \
    .orderBy("average_rating", ascending=False)


print("Top 10 filmes com melhores médias de avaliação (min. 10.000 avaliações):")
average_ratings.select("title", "average_rating", "num_ratings").show(10, truncate=False)

"""---

**Distribuição de ratings**



*   **ratings.select("rating")** : Selecionado apenas a coluna rating do DataFrame ratings
*   **.groupBy("rating")** : Agrupa os dados pela coluna rating
*   **.count()** : Conta quantas vezes cada nota (rating) aparece no DataFrame
*   **.orderBy("rating")** : Ordena os resultados pelo valor da coluna rating
*   **.show()** : Exibe o resultado na tela.
"""

ratings_distribution = ratings.select("rating") \
    .groupBy("rating") \
    .count() \
    .orderBy("rating")

ratings_distribution.show()

"""---

**Processar gêneros**


*   **split(col("genres"), "\\|")** : A função split divide o conteúdo da coluna genres em uma lista de gêneros.
*   *   O valor na coluna genres é uma string com gêneros separados por pipe (|), por exemplo: "Action|Adventure|Sci-Fi".
*   *   O comando split quebra essa string em uma lista de gêneros, como ["Action", "Adventure", "Sci-Fi"]

*   **explode(col("genres"))** : A função explode pega a lista de gêneros de cada filme e cria uma linha separada para cada gênero

*   **filter(col("genre") == "Action")** : Este comando filtra os filmes que têm o gênero "Action" na coluna genre criada na etapa anterior
"""

# Dividir a coluna 'genres' em uma lista e explodir
movies = movies.withColumn("genres", split(col("genres"), "\\|"))
movies_exploded = movies.withColumn("genre", explode(col("genres")))

# Exemplo: Filmes de Ação
action_movies = movies_exploded.filter(col("genre") == "Action")

print("Exemplo de filmes de ação:")
action_movies.show(10, truncate=False)

"""---

**Recomendação de Filmes**



*   **ratings.randomSplit([0.8, 0.2], seed=42)** : randomSplit divide o DataFrame ratings em dois conjuntos: 80% train e 20% test
*   *   O seed=42 garante que sempre que executar o código, a divisão dos dados seja a mesma.



**ALS** : O algoritmo Alternating Least Squares (ALS) é uma técnica de fatoração de matrizes usada para recomendação em sistemas baseados em dados de interação, como no caso de filmes, músicas, etc.


*   **maxIter=10** : Nº máximo de iterações que o algoritmo fará para tentar otimizar a decomposição das matrizes (reduzir o erro)
*   **regParam=0.1** : Parâmetro que ajuda a evitar o overfitting (modelo não generaliza bem para novos dados)
*  **userCol="userId"** : Coluna no DataFrame que contém os identificadores dos usuários
*   **itemCol="movieId"** : Coluna que contém os identificadores dos itens (filmes)
*   **ratingCol="rating"** : Coluna que contém as avaliações feitas pelos usuários.
*   **coldStartStrategy="drop"** : Usado para lidar com o problema de cold start (quando o modelo tenta fazer previsões para um usuário ou item que não tem dados suficientes)
*   *   **drop** : Remover os casos de cold start (usuários ou itens com pouca ou nenhuma interação nos dados)
"""

# Dividir dados em treino e teste
train, test = ratings.randomSplit([0.8, 0.2], seed=42)

# Importar ALS para recomendação
from pyspark.ml.recommendation import ALS
from pyspark.ml.evaluation import RegressionEvaluator

# Configurar modelo ALS
als = ALS(
    maxIter=10,
    regParam=0.1,
    userCol="userId",
    itemCol="movieId",
    ratingCol="rating",
    coldStartStrategy="drop"
)

"""---

# **Treinar o modelo**
"""

model = als.fit(train)

"""---

**Avaliar o modelo no conjunto de teste**


*   O método ***transform*** aplica o modelo treinado ao conjunto de teste. O conjunto de teste contém interações que o modelo ainda não viu, ou seja, avaliações dos filmes feitas pelos usuários
"""

predictions = model.transform(test)
evaluator = RegressionEvaluator(
    metricName="rmse",
    labelCol="rating",
    predictionCol="prediction"
)
rmse = evaluator.evaluate(predictions)
print(f"Root Mean Square Error (RMSE): {rmse}")

"""---

**Recomendação personalizada para o usuário id 1**


*   **model.recommendForAllUsers(10)** : Gera as 10 melhores recomendações para todos os usuários do conjunto de dados.
*   *   A função retorna um DataFrame contendo as recomendações de filmes para cada usuário.
*   **filter(col("userId") == user_id)** : Filtra o DataFrame gerado para obter apenas as recomendações do usuário com o user_id=1
"""

user_id = 1
user_recommendations = model.recommendForAllUsers(10)
recommendations = user_recommendations.filter(col("userId") == user_id)

print(f"Recomendações para o usuário {user_id}:")
recommendations.show(truncate=False)

"""---

**Recomendações com títulos**


*   **explode("recommendations")** :
*   *   A coluna recommendations, gerada pelo modelo ALS, contém uma lista de objetos (movieId e rating).
*   *   O método ***explode*** transforma essa lista em várias linhas, onde cada linha contém apenas um item da lista
*   **select("userId", explode(...))** : A nova tabela resultante terá duas colunas: *userId* e *recommendation* (contendo movieId e rating)
*   **join(movies, "movieId")** : Realiza um join entre as tabelas recommendations e movies com base na coluna movieId.
"""

recommendations = recommendations.select("userId", explode("recommendations").alias("recommendation"))
recommendations = recommendations.select("userId", col("recommendation.movieId").alias("movieId"), col("recommendation.rating").alias("predicted_rating"))

recommendations_with_titles = recommendations.join(movies, "movieId")

print(f"Recomendações para o usuário {user_id} com títulos:")
recommendations_with_titles.show(10, truncate=False)

"""---

**Visualização de Dados**
"""

# Converter distribuição de ratings para Pandas e plotar
ratings_distribution_pd = ratings_distribution.toPandas()
ratings_distribution_pd.plot(kind='bar', x='rating', y='count', legend=False, title='Distribuição de Ratings')
plt.xlabel("Rating")
plt.ylabel("Contagem")
plt.show()

"""---

**Visualizar recomendações para o usuário**
"""

user_recommendations_df = recommendations_with_titles.toPandas()
user_recommendations_df.plot(kind="barh", x="title", y="predicted_rating", title=f"Recomendações para o Usuário {user_id}")
plt.xlabel("Predicted Rating")
plt.ylabel("Título")
plt.show()

"""---

**Finalizar e salvar**
"""

# Salvar recomendações em CSV
from pyspark.sql.functions import concat_ws

# Converter a coluna 'genres' (ARRAY<STRING>) em uma string delimitada
recommendations_with_titles = recommendations_with_titles.withColumn(
    "genres", concat_ws(",", "genres")
)

# Salvar em CSV
recommendations_with_titles.write.mode("overwrite").csv("recommendations_with_titles.csv", header=True)

print("Processo concluído com sucesso!")